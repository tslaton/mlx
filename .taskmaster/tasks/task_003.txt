# Task ID: 3
# Title: Implement DataLoader class
# Status: pending
# Dependencies: 2
# Priority: high
# Description: Create the DataLoader class to handle batching, shuffling, and iteration over datasets.
# Details:
Implement a DataLoader class that:
1. Takes a Dataset instance as input
2. Supports batch creation with configurable batch size
3. Provides shuffling capabilities
4. Implements iteration protocol (__iter__, __next__)
5. Handles the last batch (potentially incomplete)

Example implementation:
```python
class DataLoader:
    def __init__(self, dataset, batch_size=1, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indices = list(range(len(dataset)))
        
    def __iter__(self):
        if self.shuffle:
            random.shuffle(self.indices)
        self.current = 0
        return self
        
    def __next__(self):
        if self.current >= len(self.indices):
            raise StopIteration
            
        batch_indices = self.indices[self.current:self.current + self.batch_size]
        batch = [self.dataset[i] for i in batch_indices]
        self.current += self.batch_size
        
        # Convert list of samples to batched tensors
        return self._collate(batch)
        
    def _collate(self, batch):
        # Implement logic to convert list of samples to batched tensors
        pass
```

The implementation should prioritize performance while maintaining a clean API.

# Test Strategy:
Test with various batch sizes, with and without shuffling. Verify that all samples are correctly yielded. Test with edge cases like batch_size=1, batch_size > dataset length, and empty datasets. Benchmark performance with large datasets.

# Subtasks:
## 1. Implement DataLoader initialization and configuration [pending]
### Dependencies: None
### Description: Create the DataLoader class with proper initialization that accepts a dataset instance and configures batch size and shuffling options.
### Details:
Create the DataLoader class with an __init__ method that takes a dataset, batch_size (default=1), and shuffle (default=False) parameters. Store these as instance variables. Initialize indices as a list of integers from 0 to len(dataset)-1. Add input validation to ensure dataset is a valid Dataset instance, batch_size is a positive integer, and shuffle is a boolean.

## 2. Implement iteration protocol methods [pending]
### Dependencies: 3.1
### Description: Add __iter__ and __next__ methods to make the DataLoader iterable, handling shuffling and batch creation.
### Details:
Implement __iter__ method that shuffles indices if self.shuffle is True, resets the current position counter to 0, and returns self. Implement __next__ method that checks if current position exceeds dataset length, raises StopIteration when exhausted, extracts batch_indices from the indices list using current position and batch_size, creates a batch by accessing dataset with these indices, increments current position by batch_size, and returns the collated batch.

## 3. Implement batch collation functionality [pending]
### Dependencies: 3.2
### Description: Create the _collate method to convert a list of individual samples into batched tensors.
### Details:
Implement the _collate method that takes a list of samples and combines them into a batched format. Handle different data types: for numeric data, convert to MLX arrays and stack them; for dict-type samples, create a dict with the same keys but values batched together; for tuple/list samples, batch each position separately. Add type checking and appropriate error messages for unsupported data types.

## 4. Handle incomplete last batch [pending]
### Dependencies: 3.2, 3.3
### Description: Modify the DataLoader to properly handle the last batch which may be smaller than the specified batch size.
### Details:
Update the __next__ method to correctly handle the case where the remaining samples are fewer than batch_size. Ensure the last batch is properly created and collated even if incomplete. Add an optional drop_last parameter to the constructor (default=False) that, when True, will drop the last batch if it's incomplete.

## 5. Optimize performance and add utility methods [pending]
### Dependencies: 3.1, 3.2, 3.3, 3.4
### Description: Optimize the DataLoader for performance and add utility methods for better usability.
### Details:
Optimize batch creation by using slicing operations where possible instead of list comprehensions. Add a reset() method to reset the iterator state without creating a new DataLoader. Implement a __len__ method that returns the number of batches (accounting for drop_last setting). Add an optional num_workers parameter (for future multi-threading support) that currently just logs a warning that it's not implemented. Document all methods with proper docstrings.

